# update_vector_db.py

import os
import shutil
from langchain_community.document_loaders import NotionDBLoader
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores.utils import filter_complex_metadata



from dotenv import load_dotenv

load_dotenv()

NOTION_API_KEY = os.getenv("NOTION_API_KEY")
NOTION_DATABASE_ID = os.getenv("NOTION_DATABASE_ID")
PERSIST_DIRECTORY = "chroma_db_notion"

def setup_vector_db():
    print("ğŸ“¥ Notion ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    loader = NotionDBLoader(
        integration_token=NOTION_API_KEY,
        database_id=NOTION_DATABASE_ID,
        request_timeout_sec=30,
    )
    docs = loader.load()
    docs = filter_complex_metadata(docs)
    print(f"âœ… ë¬¸ì„œ ìˆ˜: {len(docs)}")

    if not docs:
        print("âŒ ë¬¸ì„œ ì—†ìŒ! API í‚¤, DB ID, ê³µìœ  ì„¤ì • í™•ì¸ í•„ìš”")
        return None

    print("ğŸ§© ë¬¸ì„œ ë¶„í•  ë° ì„ë² ë”© ì¤‘...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    splits = text_splitter.split_documents(docs)

    if os.path.exists(PERSIST_DIRECTORY):
        shutil.rmtree(PERSIST_DIRECTORY)

    embeddings = OpenAIEmbeddings()

    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embeddings,
        persist_directory=PERSIST_DIRECTORY
    )
    print("âœ… ë²¡í„° DB ìƒì„± ì™„ë£Œ!")
    return vectorstore

if __name__ == "__main__":
    setup_vector_db()
